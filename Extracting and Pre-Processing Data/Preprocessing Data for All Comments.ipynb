{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data previously extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('r_india.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions for text pre-processing\n",
    "\n",
    "### \".\" punctuator has also been replaced by space so that every url can be broken down to extract valuable tokens\n",
    "### Verb abbreviated forms have been decontracted to ensure proper removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,.;_]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "#STEMMER = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\" ive \", \"i have \", phrase)\n",
    "    phrase = re.sub(r\" hes \", \" he is \", phrase)\n",
    "    phrase = re.sub(r\" shes \", \" she is \", phrase)\n",
    "    phrase = re.sub(r\"http\", \"\", phrase)\n",
    "    phrase = re.sub(r\"www\", \"\", phrase)\n",
    "    phrase = re.sub(r\"\\.com\", \"\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def conv_str(text):\n",
    "    return str(text)\n",
    "\n",
    "def cleaner(text):\n",
    "   \n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = ' '.join(decontracted(word) for word in text.split())\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    #text = ' '.join(STEMMER.stem(word) for word in text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function call for text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://youtu.be/kBvIqVr__C0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "data['title'] = data['title'].apply(conv_str)\n",
    "data['body'] = data['body'].apply(conv_str)\n",
    "data['comments'] = data['comments'].apply(conv_str)\n",
    "\n",
    "data['title'] = data['title'].apply(cleaner)\n",
    "data['body'] = data['body'].apply(cleaner)\n",
    "data['comments'] = data['comments'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>indian state ut renamed country similar popula...</td>\n",
       "      <td>https://i.redd.it/hk9o11b8dun41.png</td>\n",
       "      <td>20</td>\n",
       "      <td>nan</td>\n",
       "      <td>schadenfeuder</td>\n",
       "      <td>nice name uttar pradesh ajay bisht gonna happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>hotstar finally uploads sunday last week tonig...</td>\n",
       "      <td>https://www.hotstar.com/in/tv/last-week-tonigh...</td>\n",
       "      <td>12</td>\n",
       "      <td>nan</td>\n",
       "      <td>TimeVendor</td>\n",
       "      <td>first turning internet entire state refusing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>icse isc exam postponed due covid19 nonpolitical</td>\n",
       "      <td>https://cisce.org//UploadedFiles/PDF/COVID%201...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>DSMalhotra</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>nonpolitical friend wrote first book week givi...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/ezqw6i...</td>\n",
       "      <td>0</td>\n",
       "      <td>friend mine wrote first book music men volume ...</td>\n",
       "      <td>bitswreck</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>nonpolitical wild karnataka david attenborough...</td>\n",
       "      <td>https://youtu.be/gHSVLd4Ao60</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>sec2aux89</td>\n",
       "      <td>real david attenborough voice video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           flair                                              title  \\\n",
       "0  Non-Political  indian state ut renamed country similar popula...   \n",
       "1  Non-Political  hotstar finally uploads sunday last week tonig...   \n",
       "2  Non-Political   icse isc exam postponed due covid19 nonpolitical   \n",
       "3  Non-Political  nonpolitical friend wrote first book week givi...   \n",
       "4  Non-Political  nonpolitical wild karnataka david attenborough...   \n",
       "\n",
       "                                                 url  comms_num  \\\n",
       "0                https://i.redd.it/hk9o11b8dun41.png         20   \n",
       "1  https://www.hotstar.com/in/tv/last-week-tonigh...         12   \n",
       "2  https://cisce.org//UploadedFiles/PDF/COVID%201...          0   \n",
       "3  https://www.reddit.com/r/india/comments/ezqw6i...          0   \n",
       "4                       https://youtu.be/gHSVLd4Ao60          1   \n",
       "\n",
       "                                                body         author  \\\n",
       "0                                                nan  schadenfeuder   \n",
       "1                                                nan     TimeVendor   \n",
       "2                                                nan     DSMalhotra   \n",
       "3  friend mine wrote first book music men volume ...      bitswreck   \n",
       "4                                                nan      sec2aux89   \n",
       "\n",
       "                                            comments  \n",
       "0  nice name uttar pradesh ajay bisht gonna happy...  \n",
       "1  first turning internet entire state refusing b...  \n",
       "2                                                nan  \n",
       "3                                                nan  \n",
       "4                real david attenborough voice video  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the pre-processed data for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('pre_processed_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
