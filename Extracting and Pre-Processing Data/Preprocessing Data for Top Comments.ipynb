{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data previously extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('r_india_with_top_comment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions for text pre-processing\n",
    "\n",
    "### \".\" punctuator has also been replaced by space so that every url can be broken down to extract valuable tokens\n",
    "### Verb abbreviated forms have been decontracted to ensure proper removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,.;_]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "#STEMMER = PorterStemmer()\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\" ive \", \"i have \", phrase)\n",
    "    phrase = re.sub(r\" hes \", \" he is \", phrase)\n",
    "    phrase = re.sub(r\" shes \", \" she is \", phrase)\n",
    "    phrase = re.sub(r\"http\", \"\", phrase)\n",
    "    phrase = re.sub(r\"www\", \"\", phrase)\n",
    "    phrase = re.sub(r\"\\.com\", \"\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def conv_str(text):\n",
    "    return str(text)\n",
    "\n",
    "def cleaner(text):\n",
    "   \n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = ' '.join(decontracted(word) for word in text.split())\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    #text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    #text = ' '.join(STEMMER.stem(word) for word in text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function call for text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:357: UserWarning: \"https://youtu.be/kBvIqVr__C0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "data['title'] = data['title'].apply(conv_str)\n",
    "data['body'] = data['body'].apply(conv_str)\n",
    "data['comments'] = data['comments'].apply(conv_str)\n",
    "\n",
    "data['title'] = data['title'].apply(cleaner)\n",
    "data['body'] = data['body'].apply(cleaner)\n",
    "data['comments'] = data['comments'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>indian states uts renamed countries similar po...</td>\n",
       "      <td>https://i.redd.it/hk9o11b8dun41.png</td>\n",
       "      <td>20</td>\n",
       "      <td>nan</td>\n",
       "      <td>schadenfeuder</td>\n",
       "      <td>nice name uttar pradesh ajay bisht gonna happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>hotstar finally uploads sundays last week toni...</td>\n",
       "      <td>https://www.hotstar.com/in/tv/last-week-tonigh...</td>\n",
       "      <td>12</td>\n",
       "      <td>nan</td>\n",
       "      <td>TimeVendor</td>\n",
       "      <td>first turning internet entire state refusing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>best nonpolitical stand comedian</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g3zbrt...</td>\n",
       "      <td>9</td>\n",
       "      <td>thing related politics gives anxiety recommend...</td>\n",
       "      <td>daredevil005</td>\n",
       "      <td>abhishek upmanyu kenny sebastian biswa anubhav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>icse isc exams postponed due covid19 nonpolitical</td>\n",
       "      <td>https://cisce.org//UploadedFiles/PDF/COVID%201...</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>DSMalhotra</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Non-Political</td>\n",
       "      <td>nonpolitical friend wrote first book week givi...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/ezqw6i...</td>\n",
       "      <td>0</td>\n",
       "      <td>friend mine wrote first book music men volume ...</td>\n",
       "      <td>bitswreck</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           flair                                              title  \\\n",
       "0  Non-Political  indian states uts renamed countries similar po...   \n",
       "1  Non-Political  hotstar finally uploads sundays last week toni...   \n",
       "2  Non-Political                   best nonpolitical stand comedian   \n",
       "3  Non-Political  icse isc exams postponed due covid19 nonpolitical   \n",
       "4  Non-Political  nonpolitical friend wrote first book week givi...   \n",
       "\n",
       "                                                 url  comms_num  \\\n",
       "0                https://i.redd.it/hk9o11b8dun41.png         20   \n",
       "1  https://www.hotstar.com/in/tv/last-week-tonigh...         12   \n",
       "2  https://www.reddit.com/r/india/comments/g3zbrt...          9   \n",
       "3  https://cisce.org//UploadedFiles/PDF/COVID%201...          0   \n",
       "4  https://www.reddit.com/r/india/comments/ezqw6i...          0   \n",
       "\n",
       "                                                body         author  \\\n",
       "0                                                nan  schadenfeuder   \n",
       "1                                                nan     TimeVendor   \n",
       "2  thing related politics gives anxiety recommend...   daredevil005   \n",
       "3                                                nan     DSMalhotra   \n",
       "4  friend mine wrote first book music men volume ...      bitswreck   \n",
       "\n",
       "                                            comments  \n",
       "0  nice name uttar pradesh ajay bisht gonna happy...  \n",
       "1  first turning internet entire state refusing b...  \n",
       "2  abhishek upmanyu kenny sebastian biswa anubhav...  \n",
       "3                                                nan  \n",
       "4                                                nan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the pre-processed data for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('pre_processed_data_with_top_comment_latest_one.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
